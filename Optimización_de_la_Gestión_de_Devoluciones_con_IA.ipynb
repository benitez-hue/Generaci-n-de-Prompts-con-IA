{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sQ2Lr421fc9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ Optimizaci√≥n de la Gesti√≥n de Devoluciones con IA\n",
        "## üöÄ Implementaci√≥n de Fast Prompting en la Gesti√≥n de Devoluciones\n",
        "\n",
        "## üìå Problema y Soluci√≥n Propuesta (Resumen de la Primera Entrega)\n",
        "\n",
        "### üì¶ Problema: Gesti√≥n Ineficiente de Devoluciones en Empresas de Intermediaci√≥n de Compras Internacionales  \n",
        "\n",
        "Las empresas que act√∫an como intermediarias en compras internacionales enfrentan problemas recurrentes en la entrega de productos, generando costos adicionales y frustraci√≥n en los clientes. Entre los principales inconvenientes se encuentran:  \n",
        "\n",
        "1. **Errores en la entrega:** Productos incorrectos enviados a los clientes finales.  \n",
        "2. **Procesos de devoluci√≥n complejos:** Muchos clientes deben asumir costos de env√≠o para devolver productos err√≥neos.  \n",
        "3. **Falta de validaci√≥n autom√°tica de los paquetes antes de su despacho.**  \n",
        "4. **Mala comunicaci√≥n entre la empresa intermediaria y la tienda vendedora.**  \n",
        "5. **Requerimiento de devoluciones presenciales**, lo que no es pr√°ctico para clientes que recibieron su pedido puerta a puerta.  \n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ Soluci√≥n Propuesta: Optimizaci√≥n con IA y Fast Prompting  \n",
        "\n",
        "üí° **Implementaci√≥n de un sistema basado en IA para optimizar la gesti√≥n de devoluciones.**  \n",
        "\n",
        "### üîç Fase 1: Verificaci√≥n Autom√°tica del Pedido con IA  \n",
        "‚úÖ **Uso de Computer Vision** para analizar im√°genes del paquete y compararlas con la orden de compra.  \n",
        "‚úÖ **Escaneo de c√≥digos de barras y etiquetas RFID** para cotejar con el pedido.  \n",
        "‚úÖ **Alerta autom√°tica si hay discrepancias** antes de despachar al cliente final.  \n",
        "\n",
        "### üì¶ Fase 2: Opciones de Devoluci√≥n Simplificadas  \n",
        "‚úÖ **C√≥digo QR para devoluciones sin embalaje ni etiqueta impresa.**  \n",
        "‚úÖ **Puntos de devoluci√≥n en ubicaciones estrat√©gicas o recogida a domicilio.**  \n",
        "‚úÖ **Posibilidad de usar transportistas externos con rastreo del paquete.**  \n",
        "\n",
        "### üìú Fase 3: Seguimiento y Reembolsos Automatizados  \n",
        "‚úÖ **Si el cliente ya recibi√≥ un reembolso anticipado, se rastrea la devoluci√≥n.**  \n",
        "‚úÖ **Si el producto no es devuelto, se aplica un cobro autom√°tico.**  \n",
        "‚úÖ **El reembolso se procesa en un m√°ximo de 3 d√≠as h√°biles tras la recepci√≥n del producto.**  \n"
      ],
      "metadata": {
        "id": "aVlbzaiIfgCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar bibliotecas necesarias\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n"
      ],
      "metadata": {
        "id": "GfGMqrCVfkZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#‚É£ Fase 1: Verificaci√≥n del Pedido con IA (Visi√≥n por Computadora)\n",
        "# Cargar modelo de reconocimiento de productos (simulaci√≥n)\n",
        "# En un caso real, se entrenar√≠a un modelo para clasificar los productos recibidos\n",
        "try:\n",
        "    model = load_model('modelo_reconocimiento_productos.h5')\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Advertencia: Modelo de reconocimiento no disponible.\")\n",
        "\n",
        "def verificar_producto(imagen):\n",
        "    \"\"\"Funci√≥n para analizar la imagen del producto recibido y compararla con la orden esperada.\"\"\"\n",
        "    img = cv2.imread(imagen)\n",
        "    img = cv2.resize(img, (224, 224))  # Redimensionar para el modelo\n",
        "    img = np.expand_dims(img, axis=0)  # Agregar batch dimension\n",
        "\n",
        "    try:\n",
        "        prediccion = model.predict(img)\n",
        "        return prediccion  # Simulaci√≥n de retorno de clase de producto\n",
        "    except:\n",
        "        return \"‚ö†Ô∏è No se pudo procesar la imagen. Verifique el modelo y la imagen.\"\n",
        "\n",
        "# Ejemplo de uso:\n",
        "# verificar_producto(\"producto_recibido.jpg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDzX8prwf-OC",
        "outputId": "a411a3da-2b95-4370-923d-beb3fc2ab73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Advertencia: Modelo de reconocimiento no disponible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Dpz6pjLJkMHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tiLFqoxrkmEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fase 3: Generaci√≥n de C√≥digo QR para Devoluci√≥n Explicaci√≥n de la Fase 3 (C√≥digo QR)\n",
        "üîπ Prop√≥sito: Facilitar la devoluci√≥n sin etiquetas ni embalaje, proporcionando un c√≥digo QR que contiene la informaci√≥n clave del proceso de devoluci√≥n.\n",
        "\n",
        "üîπ C√≥mo funciona:\n",
        "\n",
        "Recibe informaci√≥n de la devoluci√≥n (ejemplo: \"Orden: 12345 - Punto de devoluci√≥n: Sucursal A\").\n",
        "Genera un c√≥digo QR con la informaci√≥n codificada.\n",
        "Guarda el c√≥digo QR como imagen (codigo_qr.png) para que pueda ser escaneado en los puntos de devoluci√≥n.\n",
        " Beneficios de la Optimizaci√≥n\n",
        "‚úÖ Visualizaci√≥n inmediata del c√≥digo QR sin necesidad de abrir el archivo manualmente.\n",
        "‚úÖ El nombre del archivo es personalizable, permitiendo generar diferentes c√≥digos sin sobreescribir."
      ],
      "metadata": {
        "id": "6OzfhJd-lyML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalaci√≥n del paquete qrcode si no est√° disponible\n",
        "try:\n",
        "    import qrcode\n",
        "    import matplotlib.pyplot as plt\n",
        "except ModuleNotFoundError:\n",
        "    !pip install qrcode[pil] matplotlib\n",
        "    import qrcode\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "def generar_codigo_qr(info_devolucion, nombre_archivo=\"codigo_qr.png\"):\n",
        "    \"\"\"\n",
        "    Genera un c√≥digo QR con los datos de devoluci√≥n, lo guarda como imagen\n",
        "    y lo muestra en pantalla.\n",
        "    \"\"\"\n",
        "\n",
        "    # Crear c√≥digo QR\n",
        "    qr = qrcode.make(info_devolucion)\n",
        "    qr.save(nombre_archivo)  # Guardar QR como imagen\n",
        "\n",
        "    # Mostrar el c√≥digo QR generado\n",
        "    plt.imshow(qr, cmap=\"gray\")\n",
        "    plt.axis(\"off\")  # Ocultar ejes\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"‚úÖ C√≥digo QR generado y guardado como: {nombre_archivo}\")\n",
        "\n",
        "# Ejemplo de uso:\n",
        "# generar_codigo_qr(\"Orden: 12345 - Punto de devoluci√≥n: Sucursal A\")\n"
      ],
      "metadata": {
        "id": "ruSywU3nmHqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librer√≠as necesarias\n",
        "import qrcode\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generar_codigo_qr(info_devolucion, nombre_archivo=\"codigo_qr.png\"):\n",
        "    \"\"\"\n",
        "    Genera un c√≥digo QR con los datos de devoluci√≥n, lo guarda como imagen\n",
        "    y lo muestra en pantalla.\n",
        "    \"\"\"\n",
        "\n",
        "    # Crear c√≥digo QR\n",
        "    qr = qrcode.make(info_devolucion)\n",
        "    qr.save(nombre_archivo)  # Guardar QR como imagen\n",
        "\n",
        "    # Mostrar el c√≥digo QR generado\n",
        "    plt.imshow(qr, cmap=\"gray\")\n",
        "    plt.axis(\"off\")  # Ocultar ejes\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"‚úÖ C√≥digo QR generado y guardado como: {nombre_archivo}\")\n",
        "\n",
        "# Ejemplo de uso:\n",
        "generar_codigo_qr(\"Orden: 12345 - Punto de devoluci√≥n: Sucursal A\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "P8_qj0BEmx2E",
        "outputId": "b6060818-135d-460c-be93-5554e62e7b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ C√≥digo QR generado y guardado como: codigo_qr.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Fase 3: Seguimiento de Reembolsos y Optimizaci√≥n Log√≠stica\n",
        "Esta fase se encarga de verificar, gestionar y automatizar el proceso de reembolsos para que el sistema controle si el cliente realmente devolvi√≥ el producto antes de procesar el reembolso.\n",
        " ¬øPara qu√© sirve esta fase?\n",
        "Cuando un cliente devuelve un producto, el reembolso no deber√≠a procesarse hasta que el producto sea recibido y validado. Esta fase automatiza ese proceso para evitar fraudes, errores o retrasos en los reembolsos.\n",
        "\n",
        "üí° Ejemplo de problema sin esta fase:\n",
        "üì¶ Un cliente devuelve un producto, pero el reembolso se procesa sin verificar si el producto realmente lleg√≥ al centro de devoluciones.\n",
        "‚û° Consecuencia: La empresa pierde dinero si el producto nunca se devuelve.\n",
        "\n",
        "üí° Soluci√≥n con IA:\n",
        "üìå Un sistema automatizado rastrea el paquete devuelto y, cuando se recibe en el almac√©n, activa autom√°ticamente el reembolso. Beneficios de esta Optimizaci√≥n\n",
        "‚úÖ Evita fraudes asegurando que solo se reembolsen pedidos realmente devueltos.\n",
        "‚úÖ Mejora la comunicaci√≥n con el cliente enviando notificaciones automatizadas.\n",
        "‚úÖ Reduce la carga operativa del equipo de atenci√≥n al cliente.\n",
        "‚úÖ Optimiza la log√≠stica al integrar una API de seguimiento de paquetes.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nJPLTTXXpah-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import requests\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "# Configuraci√≥n del servidor de correo (Ejemplo con Gmail, se puede cambiar)\n",
        "SMTP_SERVER = \"smtp.gmail.com\"\n",
        "SMTP_PORT = 587\n",
        "EMAIL_USER = \"tu_email@gmail.com\"  # Cambia por tu email\n",
        "EMAIL_PASSWORD = \"tu_contrase√±a\"   # Usa una contrase√±a de aplicaci√≥n segura\n",
        "\n",
        "def enviar_correo(destinatario, asunto, mensaje):\n",
        "    \"\"\"\n",
        "    Env√≠a un correo electr√≥nico notificando el estado del reembolso.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        msg = MIMEText(mensaje)\n",
        "        msg[\"Subject\"] = asunto\n",
        "        msg[\"From\"] = EMAIL_USER\n",
        "        msg[\"To\"] = destinatario\n",
        "\n",
        "        server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n",
        "        server.starttls()\n",
        "        server.login(EMAIL_USER, EMAIL_PASSWORD)\n",
        "        server.sendmail(EMAIL_USER, destinatario, msg.as_string())\n",
        "        server.quit()\n",
        "\n",
        "        print(f\"üì© Notificaci√≥n enviada a {destinatario}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error enviando el email: {e}\")\n",
        "\n",
        "def verificar_estado_envio(tracking_number):\n",
        "    \"\"\"\n",
        "    Simula una consulta a una API de seguimiento de paquetes.\n",
        "    (En un caso real, se usar√≠a una API de FedEx, DHL, UPS, etc.)\n",
        "    \"\"\"\n",
        "    url = f\"https://api.ejemplo-seguimiento.com/status/{tracking_number}\"  # Simulaci√≥n\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        data = response.json()\n",
        "        return data[\"status\"]  # Ejemplo: \"Entregado\", \"En tr√°nsito\", \"Pendiente de env√≠o\"\n",
        "    except:\n",
        "        return \"Error en la consulta\"\n",
        "\n",
        "def seguimiento_reembolso(orden, tracking_number, email_cliente):\n",
        "    \"\"\"\n",
        "    Verifica el estado de la devoluci√≥n usando un tracking number.\n",
        "    Si el producto fue recibido, aprueba autom√°ticamente el reembolso y env√≠a una notificaci√≥n al cliente.\n",
        "    \"\"\"\n",
        "    print(f\"üìå Consultando estado de la devoluci√≥n para la orden {orden}...\")\n",
        "\n",
        "    estado = verificar_estado_envio(tracking_number)\n",
        "    time.sleep(2)  # Simulaci√≥n de tiempo de consulta\n",
        "\n",
        "    if estado.lower() == \"entregado\":\n",
        "        print(f\"‚úÖ Producto recibido. Reembolso procesado para la orden {orden}. Ser√° acreditado en 3 d√≠as h√°biles.\")\n",
        "        enviar_correo(\n",
        "            email_cliente,\n",
        "            \"üì¢ Confirmaci√≥n de Reembolso\",\n",
        "            f\"Estimado cliente,\\n\\nHemos recibido su devoluci√≥n para la orden {orden}. Su reembolso ser√° acreditado en 3 d√≠as h√°biles.\\n\\nGracias por su paciencia.\\n\\nAtentamente,\\nEquipo de Atenci√≥n al Cliente\"\n",
        "        )\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è A√∫n no hemos recibido el producto de la orden {orden}. Estado actual: {estado}.\")\n",
        "        enviar_correo(\n",
        "            email_cliente,\n",
        "            \"üö® Devoluci√≥n Pendiente\",\n",
        "            f\"Estimado cliente,\\n\\nNo hemos recibido su devoluci√≥n para la orden {orden}. Estado actual: {estado}.\\n\\nPor favor, complete la devoluci√≥n lo antes posible para procesar su reembolso.\\n\\nAtentamente,\\nEquipo de Atenci√≥n al Cliente\"\n",
        "        )\n",
        "\n",
        "# Ejemplo de uso:\n",
        "# seguimiento_reembolso(\"12345\", \"XYZ987654\", \"cliente@example.com\")\n"
      ],
      "metadata": {
        "id": "ZwamTU6Tp9NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv src/src/src/src/*.py src/  # Mueve todos los archivos .py a src/\n",
        "!rm -rf src/src/src/           # Borra las carpetas innecesarias\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaYdCky6Td1A",
        "outputId": "6a213a85-a472-4c05-ff5a-22b4a9884999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'src/src/src/src/*.py': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPJyqD10WjFK",
        "outputId": "5e690c83-bc3b-431b-df8d-827f1537d7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".:\n",
            "codigo_qr.png\t\t\t\t\t\t README.md\t   src\n",
            "Optimizaci√≥n_de_la_Gesti√≥n_de_Devoluciones_con_IA.ipynb  requirements.txt\n",
            "\n",
            "./src:\n",
            "chatbot_reclamos.py  __pycache__\t\tverificacion_producto.py\n",
            "generar_qr.py\t     seguimiento_reembolsos.py\n",
            "\n",
            "./src/__pycache__:\n",
            "chatbot_reclamos.cpython-311.pyc  seguimiento_reembolsos.cpython-311.pyc\n",
            "generar_qr.cpython-311.pyc\t  verificacion_producto.cpython-311.pyc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"src\")  # Agrega la carpeta src al path de Python\n"
      ],
      "metadata": {
        "id": "us3_jIvXim4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from verificacion_producto import verificar_producto\n",
        "from chatbot_reclamos import generar_reclamo\n",
        "from generar_qr import generar_codigo_qr\n",
        "from seguimiento_reembolsos import seguimiento_reembolso\n"
      ],
      "metadata": {
        "id": "JBEwIP54ir0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/Generaci-n-de-Prompts-con-IA\")  # Cambia a la carpeta ra√≠z del proyecto\n"
      ],
      "metadata": {
        "id": "AG5jDdOri9tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())  # Muestra la ubicaci√≥n actual\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTjl2bt9jJwe",
        "outputId": "06ce6316-79da-42e0-98c6-a01d0f112b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Generaci-n-de-Prompts-con-IA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())  # Lista los archivos en la ubicaci√≥n actual\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJx-HarsjUGW",
        "outputId": "54a99409-8f01-47ac-98be-fafb0ae21cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['codigo_qr.png', 'Optimizaci√≥n_de_la_Gesti√≥n_de_Devoluciones_con_IA.ipynb', '.git', 'requirements.txt', 'src', 'README.md']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benitez-hue/Generaci-n-de-Prompts-con-IA.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGyDcxfEjfCi",
        "outputId": "f3db9a94-5273-441f-a688-52d216c629f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Generaci-n-de-Prompts-con-IA'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 70 (delta 23), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (70/70), 36.16 KiB | 1.45 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/content\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC_we-tJjnOW",
        "outputId": "1fd52f8a-e96d-4430-c25f-3f054b94ce5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'Generaci-n-de-Prompts-con-IA', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/Generaci-n-de-Prompts-con-IA\")  # Cambia al directorio del proyecto\n",
        "print(\"Directorio actual:\", os.getcwd())  # Verifica que est√°s en la carpeta correcta\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ9Il0w_jx5c",
        "outputId": "bab77413-9154-4a65-e80d-b33a9da833bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directorio actual: /content/Generaci-n-de-Prompts-con-IA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir())  # Muestra los archivos y carpetas dentro del proyecto\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL9o5Y2DkERW",
        "outputId": "9692c065-7cff-44cf-de84-fc2f532bb935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['codigo_qr.png', 'Optimizaci√≥n_de_la_Gesti√≥n_de_Devoluciones_con_IA.ipynb', 'Generaci-n-de-Prompts-con-IA', '.git', 'requirements.txt', 'src', 'README.md']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/Generaci-n-de-Prompts-con-IA\")  # Cambia al directorio del proyecto\n",
        "print(\"Directorio actual:\", os.getcwd())  # Verifica que est√°s en la carpeta correcta\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYwgooazkVtR",
        "outputId": "1d0b343f-e927-4e97-8203-1cbb0f777d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directorio actual: /content/Generaci-n-de-Prompts-con-IA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"src\"))  # Lista los archivos dentro de src\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JKKBbutkaMh",
        "outputId": "2ada0061-e1e8-40bd-d987-20aa53dc5af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['seguimiento_reembolsos.py', '__pycache__', 'chatbot_reclamos.py', 'verificacion_producto.py', 'generar_qr.py', '.gitkeep']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(os.path.abspath(\"src\"))  # Agrega la carpeta src al path\n"
      ],
      "metadata": {
        "id": "QA1F4cCNkhhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from verificacion_producto import verificar_producto\n",
        "from chatbot_reclamos import generar_reclamo\n",
        "from generar_qr import generar_codigo_qr\n",
        "from seguimiento_reembolsos import seguimiento_reembolso\n",
        "\n",
        "print(\"‚úÖ Importaciones exitosas\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zjdx1Vdkmmy",
        "outputId": "393227bb-c1fa-47e9-96d5-5b38c26d2c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Importaciones exitosas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFjmNup3lF42",
        "outputId": "0075852a-6835-41dd-ccc2-d5743d5b1197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openai\n",
            "tensorflow\n",
            "opencv-python\n",
            "numpy\n",
            "qrcode[pil]\n",
            "matplotlib\n",
            "requests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0wlwhrDlTCi",
        "outputId": "1a2b891c-cad0-44e4-c4bc-6caf0a272bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.63.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: qrcode[pil] in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (8.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 2)) (0.37.1)\n",
            "Requirement already satisfied: pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from qrcode[pil]->-r requirements.txt (line 5)) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 7)) (2025.1.31)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 2)) (0.45.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (0.14.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 2)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 2)) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 2)) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (2.27.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 2)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 2)) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show qrcode\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLq3lT0blYS6",
        "outputId": "345e24ef-194a-4ea7-9001-9a3cf743eee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: qrcode\n",
            "Version: 8.0\n",
            "Summary: QR Code image generator\n",
            "Home-page: https://github.com/lincolnloop/python-qrcode\n",
            "Author: Lincoln Loop\n",
            "Author-email: info@lincolnloop.com\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qrcode[pil]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7kCjZo6lhB7",
        "outputId": "8f3ad2ae-f119-4d1a-f0d6-cf7971b1abb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qrcode[pil] in /usr/local/lib/python3.11/dist-packages (8.0)\n",
            "Requirement already satisfied: pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from qrcode[pil]) (11.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import qrcode\n",
        "import openai\n",
        "import tensorflow\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "print(\"‚úÖ Todas las librer√≠as est√°n instaladas correctamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLj_J5NFlm6k",
        "outputId": "3fddc607-cc10-45da-9c2e-6a80e078f99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Todas las librer√≠as est√°n instaladas correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.verificacion_producto import verificar_producto\n",
        "from src.chatbot_reclamos import generar_reclamo\n",
        "from src.generar_qr import generar_codigo_qr\n",
        "from src.seguimiento_reembolsos import seguimiento_reembolso\n",
        "\n",
        "print(\"‚úÖ Importaciones exitosas\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI2br6eKltZe",
        "outputId": "6cb574ac-d6ba-463b-b211-89c9be564925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Importaciones exitosas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultado = verificar_producto(\"producto_recibido.jpg\")  # Aseg√∫rate de tener una imagen de prueba\n",
        "print(resultado)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7cnEp9Jl7NV",
        "outputId": "6c6ebe87-c004-4a82-e2c3-0948255f5ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Verificando imagen del producto: producto_recibido.jpg\n",
            "‚úÖ Producto verificado (simulaci√≥n)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfPGDBjVnuYW",
        "outputId": "7457e5c8-281c-4a29-b054-d81924c4f1db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  25% (1/4)\u001b[K\rremote: Compressing objects:  50% (2/4)\u001b[K\rremote: Compressing objects:  75% (3/4)\u001b[K\rremote: Compressing objects: 100% (4/4)\u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 1.12 KiB | 1.12 MiB/s, done.\n",
            "From https://github.com/benitez-hue/Generaci-n-de-Prompts-con-IA\n",
            "   da5ad94..fbc4d81  main       -> origin/main\n",
            "Updating da5ad94..fbc4d81\n",
            "Fast-forward\n",
            " src/chatbot_reclamos.py | 9 \u001b[32m++++\u001b[m\u001b[31m-----\u001b[m\n",
            " 1 file changed, 4 insertions(+), 5 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRH-Me6joV8I",
        "outputId": "3c42dcfa-5070-4769-d11a-464e0cf60bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.63.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultado = verificar_producto(\"producto_recibido.jpg\")  # Simulaci√≥n, cambia el nombre si tienes otra imagen\n",
        "print(resultado)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUi8tMemvHJA",
        "outputId": "457c10c9-c44e-46af-b10d-eb61958edd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Verificando imagen del producto: producto_recibido.jpg\n",
            "‚úÖ Producto verificado (simulaci√≥n)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add Optimizaci√≥n_de_la_Gesti√≥n_de_Devoluciones_con_IA.ipynb\n",
        "!git commit -m \"Actualizaci√≥n final del notebook\"\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2SZoVaYXc5J",
        "outputId": "7e7ece02-1129-4b79-8280-6b5271d7161b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"Sincronizaci√≥n final del proyecto\"\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ71yLBKX8LH",
        "outputId": "15b92c91-56a5-48bf-c58c-8aae3330f40e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTvD7GmoYemZ",
        "outputId": "0933bb66-c044-40fa-9409-8363fea61d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -a --amend -m \"Actualizaci√≥n forzada del notebook\"\n",
        "!git push origin main --force\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rl1-jmaY78V",
        "outputId": "2bc8ff7c-570a-4d60-b9da-300b92ed0b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main ba5230b] Actualizaci√≥n forzada del notebook\n",
            " Date: Mon Feb 17 01:48:12 2025 -0300\n",
            " 1 file changed, 2 insertions(+), 7 deletions(-)\n",
            "Enumerating objects: 5, done.\n",
            "Counting objects: 100% (5/5), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (3/3), 347 bytes | 347.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/benitez-hue/Generaci-n-de-Prompts-con-IA.git\n",
            " + 9c2b971...ba5230b main -> main (forced update)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh Optimizaci√≥n_de_la_Gesti√≥n_de_Devoluciones_con_IA.ipynb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKlokyMAbVMi",
        "outputId": "cf078e57-75d7-4f7a-b3a0-fbe3c8b326cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 34K Feb 17 04:34 Optimizaci√≥n_de_la_Gesti√≥n_de_Devoluciones_con_IA.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0Pnv2FCbeUh",
        "outputId": "2fac377b-33f3-4e2c-ab41-abca2030a681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add Optimizaci√≥n_de_la_Gesti√≥n_de_Devoluciones_con_IA.ipynb\n"
      ],
      "metadata": {
        "id": "Wrs2TJo0fY66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Actualizaci√≥n del notebook de optimizaci√≥n\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-kSEpV4fdNZ",
        "outputId": "9d3873f1-2587-488d-8438-31c13122d5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkUOAm8-fjEi",
        "outputId": "ee1853fd-041e-4337-be14-6bd7fe7acf41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push --force origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaXowpKKfuwC",
        "outputId": "3818511c-43ca-4387-ba33-030ca4409aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh Optimizaci√≥n_de_la_Gesti√≥n_de_Devoluciones_con_IA.ipynb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyFFflolf0R8",
        "outputId": "6e573592-d776-4c69-e0fc-68a503a01c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 34K Feb 17 04:34 Optimizaci√≥n_de_la_Gesti√≥n_de_Devoluciones_con_IA.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add -A\n",
        "!git commit -m \"Forzar actualizaci√≥n del notebook\"\n",
        "!git push --force origin main\n"
      ],
      "metadata": {
        "id": "gRQ0eWVff6r1",
        "outputId": "fc3d4a04-67de-4bd8-a05e-f284f1983292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generar_mensaje_personalizado(cliente, producto, valor, tipo_cliente):\n",
        "    \"\"\"\n",
        "    Genera un mensaje automatizado basado en el tipo de cliente y el valor del producto.\n",
        "\n",
        "    - cliente: Nombre del cliente\n",
        "    - producto: Producto comprado\n",
        "    - valor: Categor√≠a del valor del producto ('bajo', 'medio', 'alto')\n",
        "    - tipo_cliente: Tipo de cliente ('nuevo', 'frecuente', 'vip')\n",
        "    \"\"\"\n",
        "\n",
        "    mensajes = {\n",
        "        \"bajo\": {\n",
        "            \"nuevo\": f\"Hola {cliente}, gracias por tu compra del {producto}. ¬°Esperamos que lo disfrutes! üòä\",\n",
        "            \"frecuente\": f\"Hola {cliente}, tu {producto} ya est√° en camino. ¬°Gracias por confiar en nosotros nuevamente! üöÄ\",\n",
        "            \"vip\": f\"{cliente}, tu {producto} ya fue despachado. Como siempre, cuentas con nuestra mejor atenci√≥n. ‚≠ê\"\n",
        "        },\n",
        "        \"medio\": {\n",
        "            \"nuevo\": f\"Hola {cliente}, tu pedido de {producto} ha sido confirmado. ¬°Te enviaremos novedades pronto! üì¶\",\n",
        "            \"frecuente\": f\"{cliente}, tu {producto} est√° en camino. ¬°Gracias por seguir eligi√©ndonos! üõçÔ∏è\",\n",
        "            \"vip\": f\"{cliente}, hemos priorizado tu env√≠o de {producto}. ¬°Gracias por ser un cliente especial! ‚ú®\"\n",
        "        },\n",
        "        \"alto\": {\n",
        "            \"nuevo\": f\"Estimado {cliente}, tu pedido de {producto} ha sido procesado con prioridad. Pronto recibir√°s novedades. üì≤\",\n",
        "            \"frecuente\": f\"Hola {cliente}, tu {producto} est√° en camino. Sabemos lo importante que es para ti. üì¶\",\n",
        "            \"vip\": f\"{cliente}, tu {producto} ha sido enviado con el m√°s alto est√°ndar de seguridad. Gracias por confiar en nosotros. üèÜ\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return mensajes[valor][tipo_cliente]\n",
        "\n",
        "# **Prueba del sistema**\n",
        "if __name__ == \"__main__\":\n",
        "    clientes = [\"Mar√≠a\", \"Jos√©\", \"Laura\", \"Carlos\"]\n",
        "    productos = [\"Celular X\", \"Notebook Pro\", \"Auriculares Inal√°mbricos\"]\n",
        "    valores = [\"bajo\", \"medio\", \"alto\"]\n",
        "    tipos_clientes = [\"nuevo\", \"frecuente\", \"vip\"]\n",
        "\n",
        "    # Prueba con datos aleatorios\n",
        "    for _ in range(5):\n",
        "        cliente = random.choice(clientes)\n",
        "        producto = random.choice(productos)\n",
        "        valor = random.choice(valores)\n",
        "        tipo_cliente = random.choice(tipos_clientes)\n",
        "\n",
        "        mensaje = generar_mensaje_personalizado(cliente, producto, valor, tipo_cliente)\n",
        "        print(mensaje)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNFhqlstycKy",
        "outputId": "f16b4a39-438b-4b1a-8acc-fe4769f5bd02"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Laura, hemos priorizado tu env√≠o de Notebook Pro. ¬°Gracias por ser un cliente especial! ‚ú®\n",
            "Hola Mar√≠a, tu Auriculares Inal√°mbricos est√° en camino. Sabemos lo importante que es para ti. üì¶\n",
            "Estimado Jos√©, tu pedido de Celular X ha sido procesado con prioridad. Pronto recibir√°s novedades. üì≤\n",
            "Estimado Carlos, tu pedido de Notebook Pro ha sido procesado con prioridad. Pronto recibir√°s novedades. üì≤\n",
            "Jos√©, tu Celular X est√° en camino. ¬°Gracias por seguir eligi√©ndonos! üõçÔ∏è\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import qrcode\n",
        "\n",
        "def generar_qr_reclamo(numero_reclamo):\n",
        "    \"\"\"\n",
        "    Genera un c√≥digo QR con el n√∫mero de reclamo.\n",
        "    :param numero_reclamo: ID √∫nico del reclamo.\n",
        "    :return: Guarda la imagen del QR con el reclamo.\n",
        "    \"\"\"\n",
        "    # üîó URL o texto del QR (puede ser un link a la consulta del reclamo)\n",
        "    url_reclamo = f\"https://miempresa.com/reclamos/{numero_reclamo}\"\n",
        "\n",
        "    # üìå Crear el QR\n",
        "    qr = qrcode.QRCode(\n",
        "        version=1,\n",
        "        error_correction=qrcode.constants.ERROR_CORRECT_L,\n",
        "        box_size=10,\n",
        "        border=4,\n",
        "    )\n",
        "    qr.add_data(url_reclamo)\n",
        "    qr.make(fit=True)\n",
        "\n",
        "    # üé® Crear imagen del QR\n",
        "    img = qr.make_image(fill=\"black\", back_color=\"white\")\n",
        "\n",
        "    # üìÇ Guardar la imagen con el n√∫mero de reclamo\n",
        "    nombre_archivo = f\"qr_reclamo_{numero_reclamo}.png\"\n",
        "    img.save(nombre_archivo)\n",
        "\n",
        "    print(f\"‚úÖ QR generado: {nombre_archivo}\")\n",
        "\n",
        "# üî• **Prueba con un reclamo**\n",
        "generar_qr_reclamo(12345)  # Reemplaza con el n√∫mero de reclamo real\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpD8Gwuv97c2",
        "outputId": "0aac1518-cf13-4604-924a-bbb0dabde1c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ QR generado: qr_reclamo_12345.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qrcode[pil]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OJ1y_b8ClYt",
        "outputId": "a95b4ecb-c533-4a92-85c5-7162e97b6965"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qrcode[pil]\n",
            "  Downloading qrcode-8.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from qrcode[pil]) (11.1.0)\n",
            "Downloading qrcode-8.0-py3-none-any.whl (45 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/45.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qrcode\n",
            "Successfully installed qrcode-8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Integrar QR + Mensajes Personalizados"
      ],
      "metadata": {
        "id": "vXfoRa11F75T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import qrcode\n",
        "\n",
        "def generar_qr_reclamo(numero_reclamo):\n",
        "    \"\"\"\n",
        "    Genera un c√≥digo QR con el n√∫mero de reclamo.\n",
        "    \"\"\"\n",
        "    url_reclamo = f\"https://miempresa.com/reclamos/{numero_reclamo}\"\n",
        "\n",
        "    qr = qrcode.make(url_reclamo)  # Generar QR\n",
        "    nombre_archivo = f\"qr_reclamo_{numero_reclamo}.png\"\n",
        "\n",
        "    qr.save(nombre_archivo)  # Guardar imagen\n",
        "\n",
        "    return nombre_archivo  # Retorna el nombre del archivo QR generado\n",
        "\n",
        "\n",
        "def generar_mensaje_reclamo(nombre_cliente, numero_reclamo, producto, es_cliente_vip):\n",
        "    \"\"\"\n",
        "    Genera un mensaje personalizado para el cliente con su n√∫mero de reclamo y un tono adecuado.\n",
        "    \"\"\"\n",
        "    # Generamos el QR\n",
        "    qr = generar_qr_reclamo(numero_reclamo)\n",
        "\n",
        "    # Definir el tono del mensaje seg√∫n el producto\n",
        "    if producto.lower() in [\"notebook pro\", \"celular x\"]:\n",
        "        tono = \"formal\"\n",
        "        mensaje = f\"Estimado/a {nombre_cliente}, lamentamos el inconveniente con su {producto}. Hemos generado su reclamo con prioridad. Su c√≥digo QR de seguimiento ha sido generado.\"\n",
        "    else:\n",
        "        tono = \"amigable\"\n",
        "        mensaje = f\"{nombre_cliente}, tu reclamo por {producto} est√° en proceso. Te mantendremos informado/a. Aqu√≠ tienes tu c√≥digo QR para seguimiento.\"\n",
        "\n",
        "    # Agregar personalizaci√≥n para clientes VIP\n",
        "    if es_cliente_vip:\n",
        "        mensaje += \" üéâ ¬°Gracias por ser un cliente especial! Siempre estamos aqu√≠ para ayudarte.\"\n",
        "\n",
        "    return mensaje, qr  # Retorna el mensaje y el QR generado\n",
        "\n",
        "\n",
        "# üî• **Prueba con diferentes casos**\n",
        "mensaje, qr_generado = generar_mensaje_reclamo(\"Laura\", 56789, \"Notebook Pro\", True)\n",
        "print(\"üì© Mensaje generado:\")\n",
        "print(mensaje)\n",
        "print(f\"üìé C√≥digo QR generado: {qr_generado}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzzl65P4F886",
        "outputId": "79c71759-8c3d-43bd-d872-67b81516e891"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì© Mensaje generado:\n",
            "Estimado/a Laura, lamentamos el inconveniente con su Notebook Pro. Hemos generado su reclamo con prioridad. Su c√≥digo QR de seguimiento ha sido generado. üéâ ¬°Gracias por ser un cliente especial! Siempre estamos aqu√≠ para ayudarte.\n",
            "üìé C√≥digo QR generado: qr_reclamo_56789.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add src/generar_qr.py\n",
        "!git add src/mensajes_personalizados.py  # Si este archivo existe\n",
        "!git commit -m \"Integraci√≥n de QR con mensajes personalizados\"\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z1p1e86PQRL",
        "outputId": "934854f2-5ce7-4bad-c017-8991f4bd2639"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqZg1LgYRGH6",
        "outputId": "8fe40a67-3cf5-4f13-b7c0-29f0c53486e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Generaci-n-de-Prompts-con-IA\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGhFWV7kRopW",
        "outputId": "efac7acc-cfa9-4178-cdb1-0f6d86cdd0b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/Generaci-n-de-Prompts-con-IA'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7BiyFvqSLzC",
        "outputId": "2dc419e5-cd35-42e6-e4d4-2e6e0a24d37e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12K\n",
            "-rw-r--r-- 1 root root  681 Mar  3 22:06 qr_reclamo_12345.png\n",
            "-rw-r--r-- 1 root root  690 Mar  3 22:20 qr_reclamo_56789.png\n",
            "drwxr-xr-x 1 root root 4.0K Feb 28 14:20 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benitez-hue/Generaci-n-de-Prompts-con-IA.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "372CATKmTVll",
        "outputId": "ae5654bd-c706-4f46-b82b-042119862c44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Generaci-n-de-Prompts-con-IA'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "error: RPC failed; curl 56 GnuTLS recv error (-24): Decryption has failed.\n",
            "fatal: early EOF\n",
            "fatal: fetch-pack: invalid index-pack output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benitez-hue/Generaci-n-de-Prompts-con-IA.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiztOslTZUb-",
        "outputId": "84e2149d-f4c0-418c-e7e2-6d38c12c1ceb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Generaci-n-de-Prompts-con-IA'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 115 (delta 53), reused 8 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (115/115), 52.80 KiB | 761.00 KiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Generaci-n-de-Prompts-con-IA\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09v_e7gAcJgH",
        "outputId": "5a6acaa0-df11-4dab-eb12-2bddbf3f1792"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Generaci-n-de-Prompts-con-IA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa_Ryl0UcRWp",
        "outputId": "10e8885e-0a7b-4b83-a34f-891277529009"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 80K\n",
            "-rw-r--r-- 1 root root  65K Mar  3 23:44 Optimizaci√≥n_de_la_Gesti√≥n_de_Devoluciones_con_IA.ipynb\n",
            "-rw-r--r-- 1 root root 3.6K Mar  3 23:44 README.md\n",
            "-rw-r--r-- 1 root root   70 Mar  3 23:44 requirements.txt\n",
            "drwxr-xr-x 2 root root 4.0K Mar  3 23:44 src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add src/generar_qr.py\n",
        "!git add Optimizaci√≥n_de_la_Gesti√≥n_de_Devoluciones_con_IA.ipynb\n",
        "!git commit -m \"Integraci√≥n de QR con mensajes personalizados y actualizaci√≥n del notebook\"\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "807BabAGexON",
        "outputId": "ac9626e1-0a8d-4f7b-e7b2-f65200e87cf2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d2YY87r4e3c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh src/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNu_mEV-hGYT",
        "outputId": "2fb1ab65-4ee0-4c97-b09e-0a49e2ccf380"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'src/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_mensaje(cliente, producto, prioridad=False):\n",
        "    \"\"\"\n",
        "    Genera un mensaje personalizado seg√∫n el cliente y el producto.\n",
        "    - prioridad: si es True, el mensaje tendr√° un tono m√°s cercano.\n",
        "    \"\"\"\n",
        "    if prioridad:\n",
        "        return f\"{cliente}, hemos priorizado tu env√≠o de {producto}. ¬°Gracias por ser un cliente especial! ‚ú®\"\n",
        "    else:\n",
        "        return f\"{cliente}, tu {producto} est√° en camino. ¬°Gracias por seguir eligi√©ndonos! üõçÔ∏è\"\n",
        "\n",
        "# Prueba del c√≥digo:\n",
        "if __name__ == \"__main__\":\n",
        "    print(generar_mensaje(\"Laura\", \"Notebook Pro\", prioridad=True))\n",
        "    print(generar_mensaje(\"Jos√©\", \"Celular X\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C02vJgZuhmcY",
        "outputId": "50d9dbef-f8d3-435a-e8d6-ce724c5bf1d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Laura, hemos priorizado tu env√≠o de Notebook Pro. ¬°Gracias por ser un cliente especial! ‚ú®\n",
            "Jos√©, tu Celular X est√° en camino. ¬°Gracias por seguir eligi√©ndonos! üõçÔ∏è\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls src/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xGPHJ2QmDod",
        "outputId": "68e0ce84-b831-4915-8d88-b9e6ecd94bda"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'src/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add src/mensajes_personalizados.py\n",
        "!git commit -m \"Generaci√≥n de mensajes sin API\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL1LXww4nX1o",
        "outputId": "6683ac91-59fc-4f54-d67a-d5ca1a8775dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd1dCw6QnhhK",
        "outputId": "93f7929a-86ca-4426-f76c-79b018c699e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd  # Muestra la ruta actual en Colab\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3HDy_TasaKE",
        "outputId": "ef087214-fd23-4b35-e260-a9c647da861f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Generaci-n-de-Prompts-con-IA\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0ss1cHZsfqs",
        "outputId": "a7f93af8-77b3-4c83-8f8f-b406864211ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/Generaci-n-de-Prompts-con-IA'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl0QNCRzsj2k",
        "outputId": "f3ea0d69-acd5-4044-e8eb-3a704065c232"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benitez-hue/Generaci-n-de-Prompts-con-IA.git\n",
        "%cd Generaci-n-de-Prompts-con-IA\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zt1wgDZsnRd",
        "outputId": "c16b24c4-8b20-4763-98d8-a973dc72ad26"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Generaci-n-de-Prompts-con-IA'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 115 (delta 53), reused 8 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (115/115), 52.80 KiB | 1.06 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "/content/Generaci-n-de-Prompts-con-IA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add src/mensajes_personalizados.py\n",
        "!git commit -m \"Generaci√≥n de mensajes sin API\"\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AneMIxHnss99",
        "outputId": "0fc2d6eb-6898-4d09-c956-2a60e31a390d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: pathspec 'src/mensajes_personalizados.py' did not match any files\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p src  # Crea la carpeta src si no existe\n",
        "!touch src/mensajes_personalizados.py  # Crea el archivo vac√≠o\n"
      ],
      "metadata": {
        "id": "V0AQHfWe7bTP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/mensajes_personalizados.py\n",
        "def generar_mensaje(nombre, producto):\n",
        "    return f\"{nombre}, tu {producto} est√° en camino. ¬°Gracias por elegirnos! üöÄ\"\n",
        "\n",
        "# Prueba del c√≥digo\n",
        "if __name__ == \"__main__\":\n",
        "    print(generar_mensaje(\"Laura\", \"Notebook Pro\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMG7foju8mxu",
        "outputId": "efb3ce39-1ed7-40a3-a4bf-fcb35ed1d6be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting src/mensajes_personalizados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls src/\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Zgl5vg-0nI",
        "outputId": "6d953a5b-73a5-4420-9982-87d71a457be5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mensajes_personalizados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add src/mensajes_personalizados.py\n",
        "!git commit -m \"Agregado script de generaci√≥n de mensajes personalizados\"\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MobOosQ1-6L1",
        "outputId": "704d3581-61bf-476d-d230-ed567ffe1ce4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LQvtwnd_zQl",
        "outputId": "27eae599-65a8-43ff-93eb-05b22d287120"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benitez-hue/Generaci-n-de-Prompts-con-IA.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jbnkYn__9oF",
        "outputId": "ee14b0fa-cdd0-48b6-fab1-fba8571950ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Generaci-n-de-Prompts-con-IA'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 115 (delta 53), reused 8 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (115/115), 52.80 KiB | 1.06 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Generaci-n-de-Prompts-con-IA\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuXTQ22eADSk",
        "outputId": "50cc4b33-bbd9-44e3-91cc-137e96675df1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Generaci-n-de-Prompts-con-IA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjKUFq3mAGax",
        "outputId": "45b66784-3b10-4b6c-c1ad-975d0a41425b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add src/mensajes_personalizados.py\n",
        "!git commit -m \"Agregado mensajes personalizados sin API\"\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLYXI1zEARbZ",
        "outputId": "22e504e5-ffd1-485e-d2dd-cb4780a7a338"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: pathspec 'src/mensajes_personalizados.py' did not match any files\n",
            "Author identity unknown\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@31b680a95758.(none)')\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT5XBpYhDzt-",
        "outputId": "37a0e421-7f0b-47e1-8b51-507a397cb4c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Generaci-n-de-Prompts-con-IA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"benitml980@example.com\"\n",
        "!git config --global user.name \"benitez-hue\"\n"
      ],
      "metadata": {
        "id": "_0Zof-liEBoh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYanGph8Ecvc",
        "outputId": "967acd24-d085-4725-b3f4-30913207a9bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filter.lfs.clean=git-lfs clean -- %f\n",
            "filter.lfs.smudge=git-lfs smudge -- %f\n",
            "filter.lfs.process=git-lfs filter-process\n",
            "filter.lfs.required=true\n",
            "user.email=benitml980@example.com\n",
            "user.name=benitez-hue\n",
            "core.repositoryformatversion=0\n",
            "core.filemode=true\n",
            "core.bare=false\n",
            "core.logallrefupdates=true\n",
            "remote.origin.url=https://github.com/benitez-hue/Generaci-n-de-Prompts-con-IA.git\n",
            "remote.origin.fetch=+refs/heads/*:refs/remotes/origin/*\n",
            "branch.main.remote=origin\n",
            "branch.main.merge=refs/heads/main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile src/mensajes_personalizados.py\n",
        "def generar_mensaje(nombre, producto):\n",
        "    return f\"{nombre}, tu {producto} est√° en camino. ¬°Gracias por elegirnos! üöÄ\"\n",
        "\n",
        "# Prueba del c√≥digo\n",
        "if __name__ == \"__main__\":\n",
        "    print(generar_mensaje(\"Laura\", \"Notebook Pro\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxoqPACVFAB7",
        "outputId": "e100ad28-d4e4-4470-b30e-edd3a164531a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing src/mensajes_personalizados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls src/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOK_tbywFHG6",
        "outputId": "5ea909e0-6eab-405c-8d70-88755d1ba622"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generar_qr.py  mensajes_personalizados.py  seguimiento_reembolsos.py  verificacion_producto.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add src/mensajes_personalizados.py\n",
        "!git commit -m \"Agregado mensajes personalizados sin API\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LFDNnvOFPjd",
        "outputId": "e667059a-4b59-4847-e73c-f2905a0f04cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 9aa08bd] Agregado mensajes personalizados sin API\n",
            " 1 file changed, 6 insertions(+)\n",
            " create mode 100644 src/mensajes_personalizados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8RBYVu0GNS8",
        "outputId": "b6e307f9-0e9b-49e9-b7bf-3c3f640fc79f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Generaci-n-de-Prompts-con-IA\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjMnIoBXSTpF",
        "outputId": "f6d59df9-fa35-45e3-fbd2-8fcdb0f29588"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'Generaci-n-de-Prompts-con-IA'\n",
            "/content/Generaci-n-de-Prompts-con-IA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls src/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsdoWQAfScv0",
        "outputId": "088d702d-2ad2-42ec-8055-c381833e969e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generar_qr.py  mensajes_personalizados.py  seguimiento_reembolsos.py  verificacion_producto.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.mensajes_personalizados import generar_mensaje\n",
        "\n",
        "print(generar_mensaje(\"Laura\", \"Notebook Pro\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvhb0gbmSjok",
        "outputId": "52991e13-4e50-484f-d839-6d02f8fe1adc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Laura, tu Notebook Pro est√° en camino. ¬°Gracias por elegirnos! üöÄ\n"
          ]
        }
      ]
    }
  ]
}